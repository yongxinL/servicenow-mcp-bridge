# Task T-1.3.1: Rate Limiter

## Meta
| Field | Value |
|-------|-------|
| Task ID | T-1.3.1 |
| Milestone | M1: Foundation |
| Module | M1-MOD3: Resilience Layer |
| Priority | High |
| Effort | 3h |
| Estimated Tokens | 18K |
| Recommended Model | Sonnet |
| Dependencies | T-1.2.2 |
| Parallel Group | PG-3 |
| AC Mapping | AC-018 |

## Objective
Implement a token bucket rate limiter that throttles outbound requests to ServiceNow. The rate limiter enforces a configurable maximum requests per hour and burst size. Critically, it never drops requests — instead, it delays them until tokens are available. This protects ServiceNow instances from being overwhelmed while ensuring all requests eventually complete.

## Acceptance Criteria
- [ ] Token bucket algorithm correctly refills tokens at a steady rate based on `max_per_hour` configuration (AC-018)
- [ ] Burst capacity allows short bursts of requests up to `burst_size` tokens
- [ ] When tokens are exhausted, requests are delayed (not rejected) until a token becomes available
- [ ] `acquire()` method returns a promise that resolves when a token is available
- [ ] Default configuration: `max_per_hour: 1000`, `burst_size: 20`
- [ ] Rate limiter is stateful within a single server process (in-memory token count)
- [ ] Unit tests verify: token consumption, token refill over time, burst behavior, delay under exhaustion

## Technical Notes

### File Location
```
src/resilience/rate-limiter.ts
```

### Token Bucket Algorithm
The token bucket works as follows:
1. A bucket holds up to `burst_size` tokens
2. Tokens are added at a rate of `max_per_hour / 3600` tokens per second
3. Each request consumes 1 token
4. If tokens are available, the request proceeds immediately
5. If no tokens are available, the request waits until a token is refilled

```typescript
export class RateLimiter {
  private tokens: number;
  private lastRefill: number;
  private readonly refillRate: number; // tokens per millisecond

  constructor(
    private readonly maxPerHour: number = 1000,
    private readonly burstSize: number = 20,
  ) {
    this.tokens = burstSize;
    this.lastRefill = Date.now();
    this.refillRate = maxPerHour / (3600 * 1000); // tokens per ms
  }

  async acquire(): Promise<void> {
    this.refill();
    if (this.tokens >= 1) {
      this.tokens -= 1;
      return;
    }
    // Calculate wait time until 1 token is available
    const waitMs = Math.ceil((1 - this.tokens) / this.refillRate);
    await this.delay(waitMs);
    this.refill();
    this.tokens -= 1;
  }

  private refill(): void {
    const now = Date.now();
    const elapsed = now - this.lastRefill;
    this.tokens = Math.min(this.burstSize, this.tokens + elapsed * this.refillRate);
    this.lastRefill = now;
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

### Integration Point
The rate limiter sits in the resilience pipeline before the HTTP request is sent:
```
Module Handler -> Rate Limiter.acquire() -> ServiceNow Client -> Retry -> Circuit Breaker
```

The ServiceNow client or a resilience pipeline wrapper calls `rateLimiter.acquire()` before each outbound request.

### Key Decisions
- **Throttle, never drop**: Unlike API gateways that return 429, this rate limiter queues requests. This is appropriate because the MCP server processes requests sequentially and the caller expects every request to eventually complete.
- **In-memory only**: No persistence needed — server restart resets the bucket (acceptable for v0.1.0).
- **Single bucket**: One rate limiter for the entire server. Per-table or per-module rate limiting is out of scope for v0.1.0.
- **No queue**: Requests wait individually via `setTimeout`. A formal queue is unnecessary given MCP's sequential request processing model.
- **Testability**: Use dependency injection for time (`Date.now`) in tests to avoid real-time delays.

### Testing Strategy
- **Token consumption**: Acquire tokens up to burst size, verify they succeed immediately
- **Token exhaustion**: Exhaust all tokens, verify next acquire is delayed
- **Token refill**: Advance time, verify tokens are refilled at the correct rate
- **Burst behavior**: Verify burst allows `burst_size` immediate requests after a period of inactivity
- **Concurrency**: Verify multiple concurrent `acquire()` calls are serialized correctly (though MCP is typically sequential)

### Time Mocking
For deterministic tests, inject a clock function:
```typescript
constructor(
  maxPerHour: number = 1000,
  burstSize: number = 20,
  private readonly now: () => number = Date.now,
) { ... }
```

## Token Estimation Rationale
| Component | Tokens |
|-----------|--------|
| RateLimiter class implementation | 5K |
| Token bucket algorithm logic | 3K |
| Unit tests (consumption, refill, burst, delay) | 7K |
| Debugging buffer (15%) | 3K |
| **Total** | **18K** |
