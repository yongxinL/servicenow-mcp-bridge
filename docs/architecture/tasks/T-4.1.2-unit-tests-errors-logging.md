# Task T-4.1.2: Unit Tests for Error Handling and Logging

## Meta
| Field | Value |
|-------|-------|
| Task ID | T-4.1.2 |
| Milestone | M4 - Testing & Polish |
| Module | Error Handling & Logging |
| Priority | Medium |
| Effort | 3h |
| Estimated Tokens | 18K |
| Recommended Model | Haiku |
| Dependencies | T-1.4.1 (error normalizer), T-1.4.2 (logger setup) |
| Parallel Group | PG-6 |
| AC Mapping | AC-019 |

## Objective

Create unit tests for the error normalizer and structured logging system. These tests verify that every ServiceNow HTTP status code maps to the correct MCP error code, that empty results are handled gracefully, and that the logging system produces structured JSON output to stderr with proper correlation IDs and credential redaction.

## Acceptance Criteria

- **Error normalizer tests**:
  - HTTP 400 (Bad Request) maps to MCP error code `VALIDATION_ERROR` with ServiceNow error details from response body.
  - HTTP 401 (Unauthorized) maps to MCP error code `AUTHENTICATION_ERROR`.
  - HTTP 403 (Forbidden) maps to MCP error code `AUTHORIZATION_ERROR` with message about insufficient ACL permissions.
  - HTTP 404 (Not Found) maps to MCP error code `NOT_FOUND` with context about the missing resource (table or sys_id).
  - HTTP 429 (Too Many Requests) maps to MCP error code `RATE_LIMITED`.
  - HTTP 500 (Internal Server Error) maps to MCP error code `SERVER_ERROR`.
  - HTTP 503 (Service Unavailable) maps to MCP error code `SERVICE_UNAVAILABLE`.
  - Network errors (connection refused, timeout, DNS failure) map to MCP error code `NETWORK_ERROR`.
  - HTTP 200 with empty result array returns successful MCP result with empty array and metadata indicating "no records found".
  - All error results have `isError: true` and are valid `CallToolResult` objects.
  - Error messages are descriptive and include enough context for AI assistants to understand the issue.

- **Logger tests**:
  - **AC-019**: Given any ServiceNow API call, verify a structured JSON log entry is written to stderr containing `method`, `table`, `duration_ms`, `status_code`, and `correlation_id`.
  - Verify logs are written to stderr (not stdout, which is reserved for MCP protocol).
  - Verify child loggers inherit parent context and add their own.
  - Verify correlation IDs are unique per request and propagated through child loggers.
  - Verify credential redaction -- passwords, tokens, and Authorization header values are masked in log output.
  - Verify log level filtering works correctly (debug logs not emitted at info level).

## Technical Notes

- **Test framework**: vitest.
- **Test file location**: `tests/unit/core/error-normalizer.test.ts` and `tests/unit/core/logger.test.ts`.
- **Error normalizer testing**:
  - Create mock HTTP response objects for each status code scenario.
  - Verify the returned object shape matches `CallToolResult` with `isError: true`, `content` array with `type: "text"`, and appropriate error code/message.
  - Test edge cases: ServiceNow error response with/without error details in body, network errors with no HTTP response.
- **Logger testing**:
  - Capture stderr output using vitest's `vi.spyOn(process.stderr, 'write')` or similar.
  - Parse captured output as JSON and verify field presence and values.
  - For credential redaction, pass log entries containing passwords (`"password": "secret123"`), tokens, and Authorization headers, then verify the output replaces them with `[REDACTED]` or similar.
  - Test with pino (the chosen logging library) -- verify structured output format.
- **Haiku-suitable**: These tests follow straightforward input/output patterns (given HTTP status -> expect MCP error code). No complex logic or architecture decisions required.

## Token Estimation Rationale

| Component | Tokens |
|-----------|--------|
| Error normalizer tests (~12 test cases, one per HTTP status + edge cases) | 7K |
| Logger tests (~10 test cases) | 5K |
| Mock response objects and test helpers | 2K |
| Credential redaction test fixtures | 2K |
| Debugging and iteration buffer | 2K |
| **Total** | **18K** |
